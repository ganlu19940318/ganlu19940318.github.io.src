---
title: 机器学习模型评估与选择
date: 2019-6-13 19:02:40
categories: 技术储备
tags: [机器学习]
mathjax: true
---

----

<!-- more -->

# 1. 经验误差与过拟合

## 1.1 错误率和精度

错误率是指分类错误的样本数占样本总数的比例,如果在m个样本中有a个样本分类错误, 则错误率E = a / m.

精度= 1 - a / m, 即 精度 = 1 - 错误率.

## 1.2 误差

误差是指学习器的实际预测输出与样本的真实输出之间的差异.

训练误差(经验误差):学习器在训练集上的误差.

泛化误差:学习器在新样本上的误差.

## 1.3 过拟合和欠拟合

机器学习目标:训练在新样本上表现得很好的学习器.

过拟合:学习能力过于强大,把训练样本所包含的不太一般的特性都学到了.

欠拟合:学习能力低下,与过拟合相反.

# 2. 评估方法

## 2.1 问题分析

背景:在现实中,往往有多种学习算法选择,对同一个学习算法,当使用不同的参数配置时,也会产生不同的模型.

问题:该选择哪一个学习算法,使用哪一种参数配置?这就是模型选择问题.

理想方案:对候选模型的泛化误差进行评估,然后选择泛化误差最小的那个模型.

理想方案局限性:无法直接获得泛化误差,而训练误差又由于过拟合现象的存在不适合作为标准.

针对上述问题, 一般做法是使用测试集来测试学习器对新样本的判别能力,在测试集上的测试误差作为泛化误差的近似.

测试集应该尽可能与训练集互斥,并且从样本真实分布中独立同分布采样而得.

## 2.2 留出法

将数据集D划分为两个互斥的集合,其中一个集合作为训练集S,另一个作为测试集T,D = S ∪ T , S ∩ T = ∅,在S上训练出模型后,用T来评估其测试误差,作为对泛化误差的估计.

注意事项:

1. 测试集和训练集的划分要就尽可能保持数据分布的一致性,避免数据划分过程引入额外的偏差而对最终结果产生影响.通常采用的采样方式为分层采样.
2. 单次使用留出法得到的估计结果往往不够稳定可靠,在使用留出法时,一般要采用若干次随机划分,重复进行实验评估后取平均值作为留出法的评估结果.

## 2.3 交叉验证法

交叉验证法将数据集D划分为k个大小相似的互斥子集,即D = D1 ∪ D2 ∪ ... ∪ Dk, Di ∩ Dk = ∅(i ≠ j).每个子集Di都尽可能保持数据分布的一致性,即从D中通过分层采样得到.然后每次用k-1个子集的并集作为训练集,剩余那个子集作为测试集,这样得到k组训练/测试集,从而可进行k次训练和测试,最终返回的是这k个测试结果的均值.

交叉验证法也叫做k折交叉验证.

与留出法类似,k折交叉验证通过使用不同的划分重复p次,最终的评估结果是这p次k折交叉验证结果的均值.

留一法:假定数据集D中包含m个样本,令k=m,这种情况就是留一法.

## 2.4 自助法

某数据集D包含m个样本,对这些样本进行m次有放回的抽样,并把每次抽样结果,放到$D'$这个新的数据集里.$D'$就是训练集,而$D$ \ $D'$为测试集.

## 2.5 调参与最终模型

大多数学习算法都有参数需要设定,参数配置不同,学得模型的性能往往存在差别.因此,在进行模型评估与选择时,除了要对适用学习算法进行选择,还需要对算法参数进行设定.这就是参数调节.

模型评估与选中用于评估测试的数据集称为验证集.

# 3. 性能度量

对学习器的泛化性能进行评估,还需要有衡量模型泛化能力的评价标准,这就是性能度量.性能度量反映任务需求,在对比不同模型的能力时,使用不同的性能度量往往会导致不同的评判结果,这意味着模型的好坏是相对的,什么样的模型是好的,不仅取决于算法和数据,还决定于任务需求.

例如,给定样例集D = {(x1,y1),(x2,y2),...,(xm,ym)},其中yi是示例xi的真实标记,要评估学习器f的性能,就要把学习器的预测结果f(x)与真实标记y进行比较.

回归任务最常用的性能度量是均方误差.

$$
E\left( f;D \right) =\frac{1}{m}\sum_{i=1}^m{\left( f\left( x_i \right) -y_i \right) ^2}
$$

## 3.1 错误率和精度

错误率和精度是分类任务中常用的两种性能度量.

错误率是分类错误的样本数占样本总数的比例;
精度是分类正确的样本数占样本总数的比例.

对样例集D,错误率定义为:

![错误率](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615204321.jpg)

精度定义为:

![精度](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615204336.jpg)

## 3.2 查准率,查全率与F1

对于二分类问题,可将样例根据其真实类别与学习器预测类别的组合分为 真正例(true positive),假正例(false positive),真反例(true negative),假反例(false negative),令TP,FP,TN,FN分别表示其对应的样例数,则TP+FP+TN+FN=样例总数,分类结果的混淆矩阵如下图.

![混淆矩阵](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615205242.jpg)

查准率P与查全率R分别定义为

$$
P=\frac{TP}{TP+FP}
$$

$$
R=\frac{TP}{TP+FN}
$$

查准率P与查全率R是一堆矛盾的度量,一般查准率高时,查全率往往偏低,而查全率高时,查准率往往偏低.

下面是P-R曲线,它使用查全率和查准率作为横,纵轴.
![P-R曲线](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615205811.jpg)

平衡点(BEP)是其的一个度量,它是查准率P等于查全率R时的取值.平衡点约大,效果越好.

另一种是F1度量.

![F1度量](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615210058.jpg)

F1度量的一般形式Fβ,能让我们表达出对 查准率 / 查全率的不同偏好.

![Fβ](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615210228.jpg)

其中β > 0度量了查全率对查准率的相对重要性.
β = 1时, 退化为标准的F1;
β > 1时, 查全率有更大影响;
β < 1时. 查准率有更大影响.

很多时候有多个二分类混淆矩阵,我们希望在n个二分类混淆矩阵上综合考察查全率和查准率.

一种做法是现在各个二分类混淆矩阵上分别计算出查全率和查准率,记为(P1,R1),(P2,R2),...,(Pn,Rn),再计算平均值,这样就得到宏查准率(macro-P),宏查全率(macro-R),以及相应的宏F1(macro-F1).

![宏](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615212918.jpg)

还可以将各二分类混淆矩阵的相应元素进行平均得到TP,FP,TN,FN的平均值,记为$\overline{TP},\ \overline{FP},\ \overline{TN},\ \overline{FN}$,再基于这些平均值计算出微查准率(micro-P),微查全率(micro-R)和微F1(micro-F1).

![微](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615213327.jpg)

![微](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615213333.jpg)

## 3.3 ROC与AUC

ROC(Receiver Operating Characteristic),全称是受试者工作特征.
它的纵轴是真正例率(True Positive Rate,TPR)
它的横轴是假正例率(False Positive Rate, FPR)

![ROC](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615214341.jpg)

ROC曲线图:

![ROC与AUC](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615214613.jpg)

AUC是指ROC曲线下的面积,是ROC曲线的度量.

## 3.4 代价敏感错误率与代价曲线

以二分类任务为例,根据任务的领域知识设定一个代价矩阵,其中,costij表示将第i类样本预测为第j类的样本的代价.一般来说,costii=0.

![代价矩阵](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615215558.jpg)

若将第0类作为正类,第1类作为反类,令D+与D-分别代表样例集D的正例子集和反例子集,则代价敏感错误率为:

![代价敏感错误率](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615215838.jpg)

在非均等代价下,ROC曲线不能直接反映出学习器的期望总体代价,而代价曲线可以达到该目的.

代价曲线的横轴是取值为[0,1]的正例概率代价:

![代价曲线](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615220427.jpg)

其中p是样例为正例的概率.

纵轴是取值为[0,1]的归一化代价:

![代价曲线](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615220433.jpg)

其中,FNR = 1 - TPR, 是假反例率.

代价曲线的绘制:

设ROC曲线上点的坐标为(TPR，FPR),则可相应计算出FNR=1-TPR,然后在代价平面上绘制一条从(0,FPR) 到(1,FNR) 的线段,线段下的面积即表示了该条件下的期望总体代价,如此将ROC 曲线土的每个点转化为代价平面上的一条线段,然后取所有线段的下界,围成的面积即为在所有条件下学习器的期望总体代价.

![代价曲线](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/TIM%E6%88%AA%E5%9B%BE20190615220900.jpg)

# 4. 参考链接

[< < 机器学习 > >(周志华)](https://blogpictures-1257055754.cos.ap-guangzhou.myqcloud.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%91%A8%E5%BF%97%E5%8D%8E.pdf)
